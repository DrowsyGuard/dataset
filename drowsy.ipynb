{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9b250f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In a notebook cell\n",
    "# !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "556a0e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Library \n",
    "\n",
    "import os\n",
    "import json\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "import time\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "from typing import List, Dict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "aa6465a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_version_dir(base=\"landmarks\"):\n",
    "    Path(base).mkdir(exist_ok=True)\n",
    "    existing_versions = [\n",
    "        int(d.name[1:]) for d in Path(base).iterdir()\n",
    "        if d.is_dir() and d.name.startswith(\"v\") and d.name[1:].isdigit()\n",
    "    ]\n",
    "    next_version = max(existing_versions + [0]) + 1\n",
    "    version_path = Path(base) / f\"v{next_version}\"\n",
    "    small_dir = version_path / \"small\"\n",
    "    full_dir = version_path / \"full\"\n",
    "    small_dir.mkdir(parents=True, exist_ok=True)\n",
    "    full_dir.mkdir(parents=True, exist_ok=True)\n",
    "    return {\n",
    "        \"version\": next_version,\n",
    "        \"small_dir\": small_dir,\n",
    "        \"full_dir\": full_dir\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9b5801c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1749098791.825257 3520520 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M4 Pro\n",
      "W0000 00:00:1749098791.826526 3617385 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    }
   ],
   "source": [
    "# Initialize MediaPipe Face Mesh globally\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(\n",
    "    static_image_mode=True,\n",
    "    max_num_faces=1,\n",
    "    refine_landmarks=True,\n",
    "    min_detection_confidence=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "49375308",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1749098791.833322 3617382 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    }
   ],
   "source": [
    "def prepare_createml_dataset(dataset, output_dir=\"createml_data\"):\n",
    "    \"\"\"\n",
    "    Create CreateML dataset structure and save images for both train and test separately.\n",
    "    Returns paths to train and test directories.\n",
    "    \"\"\"\n",
    "    print(\"üöÄ Starting CreateML dataset preparation...\")\n",
    "    \n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Create separate directories for train and test\n",
    "    train_dir = os.path.join(output_dir, \"train\")\n",
    "    test_dir = os.path.join(output_dir, \"test\")\n",
    "    os.makedirs(train_dir, exist_ok=True)\n",
    "    os.makedirs(test_dir, exist_ok=True)\n",
    "    \n",
    "    # Create label subdirectories\n",
    "    for split_dir in [train_dir, test_dir]:\n",
    "        for label_name in ['awake', 'drowsy']:\n",
    "            label_dir = os.path.join(split_dir, label_name)\n",
    "            os.makedirs(label_dir, exist_ok=True)\n",
    "    \n",
    "    train_paths = []\n",
    "    test_paths = []\n",
    "    \n",
    "    # Process train split\n",
    "    print(\"üíæ Saving train images...\")\n",
    "    for idx, item in enumerate(tqdm(dataset['train'], desc=\"Train images\")):\n",
    "        label_name = 'awake' if item['label'] == 0 else 'drowsy'\n",
    "        filename = f\"train_{label_name}_{idx:05d}.jpg\"\n",
    "        filepath = os.path.join(train_dir, label_name, filename)\n",
    "        item['image'].save(filepath, 'JPEG', quality=95)\n",
    "        train_paths.append(filepath)\n",
    "    \n",
    "    # Process test split\n",
    "    print(\"üíæ Saving test images...\")\n",
    "    for idx, item in enumerate(tqdm(dataset['test'], desc=\"Test images\")):\n",
    "        label_name = 'awake' if item['label'] == 0 else 'drowsy'\n",
    "        filename = f\"test_{label_name}_{idx:05d}.jpg\"\n",
    "        filepath = os.path.join(test_dir, label_name, filename)\n",
    "        item['image'].save(filepath, 'JPEG', quality=95)\n",
    "        test_paths.append(filepath)\n",
    "    \n",
    "    print(f\"‚úÖ Dataset preparation complete!\")\n",
    "    print(f\"üìä Train images: {len(train_paths)}, Test images: {len(test_paths)}\")\n",
    "    \n",
    "    return train_paths, test_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "792b7154",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_landmarks(image_path):\n",
    "    \"\"\"Extract 468 facial landmarks from a single image using MediaPipe Face Mesh.\"\"\"\n",
    "    try:\n",
    "        image = cv2.imread(image_path)\n",
    "        if image is None:\n",
    "            return None\n",
    "        \n",
    "        # Resize for faster processing\n",
    "        image = cv2.resize(image, (640, 480))\n",
    "        rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        results = face_mesh.process(rgb_image)\n",
    "        \n",
    "        if results.multi_face_landmarks:\n",
    "            landmarks = []\n",
    "            for lm in results.multi_face_landmarks[0].landmark:\n",
    "                landmarks.append({'x': lm.x, 'y': lm.y, 'z': lm.z})\n",
    "            \n",
    "            # Clean up memory\n",
    "            del image, rgb_image, results\n",
    "            gc.collect()\n",
    "            \n",
    "            return landmarks\n",
    "        \n",
    "        # Clean up even when no face detected\n",
    "        del image, rgb_image, results\n",
    "        gc.collect()\n",
    "        return None\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error processing {image_path}: {e}\")\n",
    "        gc.collect()\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ebd2d263",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LandmarkProcessor:\n",
    "    \"\"\"Processes batches of images for landmark extraction.\"\"\"\n",
    "    \n",
    "    def __init__(self, extract_func):\n",
    "        self.extract_func = extract_func\n",
    "    \n",
    "    def process_batch(self, image_paths_batch: List[str]) -> List[Dict]:\n",
    "        \"\"\"Process a batch of images and return landmark data.\"\"\"\n",
    "        batch_results = []\n",
    "        for image_path in image_paths_batch:\n",
    "            try:\n",
    "                landmarks = self.extract_func(image_path)\n",
    "                if landmarks:\n",
    "                    # Determine label from path\n",
    "                    label = 'drowsy' if 'drowsy' in image_path.lower() else 'awake'\n",
    "                    batch_results.append({\n",
    "                        'image_path': image_path,\n",
    "                        'landmarks': landmarks,\n",
    "                        'label': label\n",
    "                    })\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è Error processing {image_path}: {e}\")\n",
    "        return batch_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c12b7eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_with_threading(image_paths, extract_landmarks_func, batch_size=200, num_threads=8, phase_name=\"\"):\n",
    "    \"\"\"Process images with multithreading and return landmarks + DataFrame.\"\"\"\n",
    "    print(f\"üßµ Starting {phase_name} processing:\")\n",
    "    print(f\"   üìä Images: {len(image_paths)}, Batch size: {batch_size}, Threads: {num_threads}\")\n",
    "    \n",
    "    # Create batches\n",
    "    batches = [image_paths[i:i + batch_size] for i in range(0, len(image_paths), batch_size)]\n",
    "    print(f\"üì¶ Created {len(batches)} batches\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    all_landmarks = []\n",
    "    \n",
    "    # Process with ThreadPoolExecutor\n",
    "    with ThreadPoolExecutor(max_workers=num_threads) as executor:\n",
    "        processor = LandmarkProcessor(extract_landmarks_func)\n",
    "        future_to_idx = {\n",
    "            executor.submit(processor.process_batch, batch): idx\n",
    "            for idx, batch in enumerate(batches)\n",
    "        }\n",
    "        \n",
    "        # Process results with progress bar\n",
    "        for future in tqdm(as_completed(future_to_idx), total=len(batches), desc=f\"{phase_name} batches\"):\n",
    "            batch_idx = future_to_idx[future]\n",
    "            try:\n",
    "                batch_result = future.result()\n",
    "                all_landmarks.extend(batch_result)\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Batch {batch_idx+1} failed: {e}\")\n",
    "    \n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"‚úÖ {phase_name} processing complete!\")\n",
    "    print(f\"   üìä Processed: {len(all_landmarks)}/{len(image_paths)} images\")\n",
    "    print(f\"   ‚è±Ô∏è Time: {total_time:.2f}s, Speed: {len(all_landmarks)/total_time:.2f} images/sec\")\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    csv_rows = []\n",
    "    for item in all_landmarks:\n",
    "        row = {'image_path': item['image_path'], 'label': item['label']}\n",
    "        \n",
    "        # Add landmark coordinates\n",
    "        for i, lm in enumerate(item['landmarks']):\n",
    "            row[f'landmark_{i}_x'] = lm['x']\n",
    "            row[f'landmark_{i}_y'] = lm['y']\n",
    "            row[f'landmark_{i}_z'] = lm['z']\n",
    "        \n",
    "        # Add computed features (EAR, MAR)\n",
    "        if len(item['landmarks']) >= 468:\n",
    "            # Eye Aspect Ratio calculation\n",
    "            left_eye_idx = [362, 385, 387, 263, 373, 380]\n",
    "            right_eye_idx = [33, 160, 158, 133, 153, 144]\n",
    "            \n",
    "            def calculate_ear(eye_points):\n",
    "                try:\n",
    "                    landmarks = item['landmarks']\n",
    "                    v1 = np.linalg.norm(np.array([\n",
    "                        landmarks[eye_points[1]]['x'] - landmarks[eye_points[5]]['x'],\n",
    "                        landmarks[eye_points[1]]['y'] - landmarks[eye_points[5]]['y']\n",
    "                    ]))\n",
    "                    v2 = np.linalg.norm(np.array([\n",
    "                        landmarks[eye_points[2]]['x'] - landmarks[eye_points[4]]['x'],\n",
    "                        landmarks[eye_points[2]]['y'] - landmarks[eye_points[4]]['y']\n",
    "                    ]))\n",
    "                    h = np.linalg.norm(np.array([\n",
    "                        landmarks[eye_points[0]]['x'] - landmarks[eye_points[3]]['x'],\n",
    "                        landmarks[eye_points[0]]['y'] - landmarks[eye_points[3]]['y']\n",
    "                    ]))\n",
    "                    return (v1 + v2) / (2.0 * h) if h > 0 else 0.0\n",
    "                except:\n",
    "                    return 0.0\n",
    "            \n",
    "            left_ear = calculate_ear(left_eye_idx)\n",
    "            right_ear = calculate_ear(right_eye_idx)\n",
    "            row['left_eye_ear'] = left_ear\n",
    "            row['right_eye_ear'] = right_ear\n",
    "            row['avg_eye_ear'] = (left_ear + right_ear) / 2.0\n",
    "            \n",
    "            # Mouth Aspect Ratio\n",
    "            mouth_idx = [61, 84, 17, 314, 405, 320]\n",
    "            try:\n",
    "                landmarks = item['landmarks']\n",
    "                v1 = np.linalg.norm(np.array([\n",
    "                    landmarks[mouth_idx[1]]['x'] - landmarks[mouth_idx[5]]['x'],\n",
    "                    landmarks[mouth_idx[1]]['y'] - landmarks[mouth_idx[5]]['y']\n",
    "                ]))\n",
    "                v2 = np.linalg.norm(np.array([\n",
    "                    landmarks[mouth_idx[2]]['x'] - landmarks[mouth_idx[4]]['x'],\n",
    "                    landmarks[mouth_idx[2]]['y'] - landmarks[mouth_idx[4]]['y']\n",
    "                ]))\n",
    "                h_m = np.linalg.norm(np.array([\n",
    "                    landmarks[mouth_idx[0]]['x'] - landmarks[mouth_idx[3]]['x'],\n",
    "                    landmarks[mouth_idx[0]]['y'] - landmarks[mouth_idx[3]]['y']\n",
    "                ]))\n",
    "                row['mouth_aspect_ratio'] = (v1 + v2) / (2.0 * h_m) if h_m > 0 else 0.0\n",
    "            except:\n",
    "                row['mouth_aspect_ratio'] = 0.0\n",
    "        \n",
    "        csv_rows.append(row)\n",
    "    \n",
    "    landmark_df = pd.DataFrame(csv_rows)\n",
    "    print(f\"üîÑ Created DataFrame: {landmark_df.shape[0]} rows, {landmark_df.shape[1]} columns\")\n",
    "    \n",
    "    return all_landmarks, landmark_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c9663684",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_separate_datasets(\n",
    "    train_paths, test_paths, extract_landmarks_func, \n",
    "    small_batch_size=5, full_batch_size=200, num_threads=8,\n",
    "    csv_train_path=\"landmarks_train.csv\", csv_test_path=\"landmarks_test.csv\",\n",
    "    json_train_path=\"landmarks_train.json\", json_test_path=\"landmarks_test.json\"\n",
    "):\n",
    "    \"\"\"Process train and test datasets completely separately.\"\"\"\n",
    "    print(\"üöÄ Starting separate train/test landmark processing...\")\n",
    "\n",
    "    # Phase 1: Small batch validation\n",
    "    print(\"üß™ Testing pipeline with small batch...\")\n",
    "    small_paths = train_paths[:small_batch_size]\n",
    "    small_landmarks, small_df = process_with_threading(\n",
    "        small_paths, extract_landmarks_func,\n",
    "        batch_size=small_batch_size,\n",
    "        num_threads=min(2, num_threads),\n",
    "        phase_name=\"VALIDATION\"\n",
    "    )\n",
    "\n",
    "    if not small_landmarks:\n",
    "        print(\"‚ùå Pipeline validation failed, exiting.\")\n",
    "        return None\n",
    "\n",
    "    print(f\"‚úÖ Pipeline validated with {len(small_landmarks)} images\")\n",
    "    cont = input(\"Proceed with full dataset processing? (y/n): \").strip().lower()\n",
    "    if cont != 'y':\n",
    "        print(\"‚èπÔ∏è Aborting after validation.\")\n",
    "        return None\n",
    "\n",
    "    # Phase 2: Process TRAINING dataset\n",
    "    print(\"üîÑ Processing TRAINING dataset...\")\n",
    "    train_landmarks, train_df = process_with_threading(\n",
    "        train_paths, extract_landmarks_func,\n",
    "        batch_size=full_batch_size,\n",
    "        num_threads=num_threads,\n",
    "        phase_name=\"TRAIN\"\n",
    "    )\n",
    "\n",
    "    if train_landmarks:\n",
    "        os.makedirs(os.path.dirname(csv_train_path), exist_ok=True)\n",
    "        with open(json_train_path, 'w') as f:\n",
    "            json.dump(train_landmarks, f, indent=2)\n",
    "        train_df.to_csv(csv_train_path, index=False)\n",
    "        print(f\"üíæ Training data saved: {csv_train_path} ({len(train_df)} samples)\")\n",
    "        print(f\"üíæ Raw landmarks backup saved: {json_train_path}\")\n",
    "        \n",
    "        train_labels = train_df['label'].value_counts()\n",
    "        print(f\"   üìä Train label distribution: {train_labels.to_dict()}\")\n",
    "\n",
    "    # Phase 3: Process TESTING dataset\n",
    "    print(\"üîÑ Processing TESTING dataset...\")\n",
    "    test_landmarks, test_df = process_with_threading(\n",
    "        test_paths, extract_landmarks_func,\n",
    "        batch_size=full_batch_size,\n",
    "        num_threads=num_threads,\n",
    "        phase_name=\"TEST\"\n",
    "    )\n",
    "\n",
    "    if test_landmarks:\n",
    "        os.makedirs(os.path.dirname(csv_test_path), exist_ok=True)\n",
    "        with open(json_test_path, 'w') as f:\n",
    "            json.dump(test_landmarks, f, indent=2)\n",
    "        test_df.to_csv(csv_test_path, index=False)\n",
    "        print(f\"üíæ Testing data saved: {csv_test_path} ({len(test_df)} samples)\")\n",
    "        print(f\"üíæ Raw landmarks backup saved: {json_test_path}\")\n",
    "\n",
    "        test_labels = test_df['label'].value_counts()\n",
    "        print(f\"   üìä Test label distribution: {test_labels.to_dict()}\")\n",
    "\n",
    "    print(\"‚úÖ Separate train/test processing complete!\")\n",
    "    return {\n",
    "        'train_samples': len(train_df) if train_landmarks else 0,\n",
    "        'test_samples': len(test_df) if test_landmarks else 0\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c22efb",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[70]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_dataset\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Assumed these are your local function definitions\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      7\u001b[39m     get_next_version_dir,\n\u001b[32m      8\u001b[39m     prepare_createml_dataset,\n\u001b[32m      9\u001b[39m     process_separate_datasets,\n\u001b[32m     10\u001b[39m     extract_landmarks,\n\u001b[32m     11\u001b[39m     face_mesh  \u001b[38;5;66;03m# assumed to be an initialized MediaPipe face mesh object\u001b[39;00m\n\u001b[32m     12\u001b[39m )\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m     15\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33müöÄ Starting Driver Drowsiness Landmark Extraction...\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'utils'"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print(\"üöÄ Starting Driver Drowsiness Landmark Extraction...\")\n",
    "\n",
    "    # Load dataset\n",
    "    print(\"üì• Loading dataset from Hugging Face...\")\n",
    "    dataset = load_dataset(\"akahana/Driver-Drowsiness-Dataset\")\n",
    "    print(f\"üìä Dataset loaded - Train: {len(dataset['train'])}, Test: {len(dataset['test'])}\")\n",
    "\n",
    "    # Create both full and small versions\n",
    "    print(\"üìÇ Creating small and full dataset splits...\")\n",
    "    small_dataset = {\n",
    "        'train': dataset['train'].select(range(min(200, len(dataset['train'])))),\n",
    "        'test': dataset['test'].select(range(min(100, len(dataset['test']))))\n",
    "    }\n",
    "    full_dataset = {\n",
    "        'train': dataset['train'],\n",
    "        'test': dataset['test']\n",
    "    }\n",
    "\n",
    "    # Get versioned output directories\n",
    "    version_info = get_next_version_dir()\n",
    "    print(f\"üìÅ Using version v{version_info['version']}\")\n",
    "\n",
    "    print(\"üíæ Preparing image files for SMALL dataset...\")\n",
    "    small_train_paths, small_test_paths = prepare_createml_dataset(\n",
    "        small_dataset,\n",
    "        output_dir=str(version_info[\"small_dir\"])\n",
    "    )\n",
    "\n",
    "    print(\"üíæ Preparing image files for FULL dataset...\")\n",
    "    full_train_paths, full_test_paths = prepare_createml_dataset(\n",
    "        full_dataset,\n",
    "        output_dir=str(version_info[\"full_dir\"])\n",
    "    )\n",
    "\n",
    "    # Settings info\n",
    "    print(\"\\nüîß Optimized settings:\")\n",
    "    print(\"   - Small batch size: 5\")\n",
    "    print(\"   - Full batch size: 200\")\n",
    "    print(\"   - Threads: 8\")\n",
    "    print(f\"   - Output directory: {version_info['full_dir'].parent}/v{version_info['version']}\")\n",
    "\n",
    "    # Process SMALL dataset\n",
    "    print(\"\\nüîé Processing SMALL dataset...\")\n",
    "    results_small = process_separate_datasets(\n",
    "        small_train_paths, small_test_paths, extract_landmarks,\n",
    "        small_batch_size=5,\n",
    "        full_batch_size=200,\n",
    "        num_threads=8,\n",
    "        csv_train_path=version_info[\"small_dir\"] / \"landmarks_train.csv\",\n",
    "        csv_test_path=version_info[\"small_dir\"] / \"landmarks_test.csv\",\n",
    "        json_train_path=version_info[\"small_dir\"] / \"landmarks_train.json\",\n",
    "        json_test_path=version_info[\"small_dir\"] / \"landmarks_test.json\"\n",
    "    )\n",
    "\n",
    "    # Process FULL dataset\n",
    "    print(\"\\nüöÄ Processing FULL dataset...\")\n",
    "    results_full = process_separate_datasets(\n",
    "        full_train_paths, full_test_paths, extract_landmarks,\n",
    "        small_batch_size=5,\n",
    "        full_batch_size=200,\n",
    "        num_threads=8,\n",
    "        csv_train_path=version_info[\"full_dir\"] / \"landmarks_train.csv\",\n",
    "        csv_test_path=version_info[\"full_dir\"] / \"landmarks_test.csv\",\n",
    "        json_train_path=version_info[\"full_dir\"] / \"landmarks_train.json\",\n",
    "        json_test_path=version_info[\"full_dir\"] / \"landmarks_test.json\"\n",
    "    )\n",
    "\n",
    "    # Final summary for SMALL\n",
    "    print(f\"\\nüìà SMALL Dataset Results:\")\n",
    "    print(f\"   Training samples: {results_small['train_samples']}\")\n",
    "    print(f\"   Testing samples: {results_small['test_samples']}\")\n",
    "\n",
    "    # Final summary for FULL\n",
    "    print(f\"\\nüìà FULL Dataset Results:\")\n",
    "    print(f\"   Training samples: {results_full['train_samples']}\")\n",
    "    print(f\"   Testing samples: {results_full['test_samples']}\")\n",
    "    print(f\"   Output: {version_info['full_dir']}\")\n",
    "\n",
    "    print(\"\\nüìã Next Steps:\")\n",
    "    print(f\"   1. Use .csv files for CreateML training and testing\")\n",
    "    print(f\"   2. .json files are available for backup/analysis\")\n",
    "\n",
    "    # Clean up MediaPipe\n",
    "    face_mesh.close()\n",
    "    print(\"‚úÖ All processing complete!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
